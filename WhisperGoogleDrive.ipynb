{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukaraju2003/WhisperGoogleDrive/blob/main/WhisperGoogleDrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're looking at this on GitHub and new to Python Notebooks or Colab, click the Google Colab badge above 👆\n",
        "\n",
        "#OpenAI Whisper and Google Drive integration for transcribing audio files\n",
        "\n",
        "📺 Getting started video: https://youtu.be/yVLhG4-7Sj4\n",
        "\n",
        "###This notebook will transcribe all the audio files in a Google Drive folder\n",
        "\n",
        "*Note: This requires giving the application permission to connect to your drive. Only you will have access to the contents of your drive, but please read the warnings carefully.*\n",
        "\n",
        "This notebook application:\n",
        "1. Connects to your Google Drive when you give it permission.\n",
        "2. Creates a WhisperAudio folder and two subfolders (ProcessedAudio and TextFiles.)\n",
        "3. When you run the application it will search for all the audio files (.mp3 and .m4a) in your WhisperAudio folder, transcribe them and then move the file to /ProcessedAudio and save the transcript to /TextFiles.\n",
        "\n",
        "###**For faster performance set your runtime to \"GPU\"**\n",
        "*Click on \"Runtime\" in the menu and click \"Change runtime type\". Select \"GPU\".*\n",
        "\n",
        "\n",
        "**Note: If you add a new file after running this application you'll need to remount the drive in step 1 to make them searchable**"
      ],
      "metadata": {
        "id": "mwJYcVNBcKpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Install the required code libraries"
      ],
      "metadata": {
        "id": "6uzeghNJgTgD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YDZ2XzKIDLsA",
        "outputId": "9f91fb2e-45f9-4ffa-d882-9745cc59988b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-pcz24g05\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-pcz24g05\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.10.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Collecting lit\n",
            "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=796926 sha256=fa5d206ab7ad5d0f31b77999f06f2b79f3934485d994768a8707ddd9deae9fb0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oy9cs8xo/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=bc6d2e1f1597ff7f2dba1cd480cc6d2fd9cd5503c83d2b8da3a05cdc55299c24\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: lit, ffmpeg-python, triton, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 lit-16.0.0 openai-whisper-20230314 tiktoken-0.3.1 triton-2.0.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,019 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,549 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,003 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,026 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,314 kB]\n",
            "Fetched 10.3 MB in 2s (5,202 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "23 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 23 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.3.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (67.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (23.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:17<00:00, 26.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install librosa\n",
        "\n",
        "import whisper\n",
        "import time\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import re\n",
        "import os\n",
        "\n",
        "# model = whisper.load_model(\"tiny.en\")\n",
        "# model = whisper.load_model(\"base.en\")   \n",
        "model = whisper.load_model(\"small.en\") # load the small model\n",
        "# model = whisper.load_model(\"medium.en\")\n",
        "# model = whisper.load_model(\"large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Allow access to your Google Drive and add new folders"
      ],
      "metadata": {
        "id": "4rhtpcTkgKrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YeXdboeC8eX",
        "outputId": "a264e27e-ccdd-469c-db30-bcdc1ddd7e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# This will create the WhisperAudio files if they don't exist.\n",
        "folders =  [\"WhisperAudio/\", \"WhisperAudio/ProcessedAudio/\", \"WhisperAudio/TextFiles/\"]\n",
        "for folder in folders:\n",
        "  path = \"/content/drive/MyDrive/\" + folder\n",
        "  if not os.path.exists(path): # Create the folder if it does not exist\n",
        "    os.mkdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Upload any audio files you want transcribed in the \"WhisperAudio\" folder in your Google Drive."
      ],
      "metadata": {
        "id": "Qg3uGr5If5oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Let the application search for new files and transcribe the audio files and save them to your Google Drive"
      ],
      "metadata": {
        "id": "tXoptztJ56eH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kBmTS6IuPh3M",
        "outputId": "c61e232a-5f70-482b-afe6-b164e4804700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/WhisperAudio/saved.mp3\n",
            "Processing saved.mp3...\n",
            "1 words processed\n",
            "Transcription of saved.mp3:\n",
            "\n",
            "Hi, my name is Julie Saha. I was born and raised in MPJ I am an outbound customer care and semi-technical processes. In my leisure time, I like to spend most of my time reading books, listening to music, traveling and of course spending time with my kids. Talking about my strength, I would say I am self-motivated. I do not need someone else to push me to achieve my goals and dreams. And about weakness, I would say I look for perfection. I completely understand it is humanly not always possible to be perfect. Hence, I am working on my weakness to make sure that I figure out a way to get things done in a better way even if it is not perfect. And yes, so that's mostly about me. Thank you so much for giving me this opportunity to talk about myself and introduce myself to you all. Hope to hear from you soon. Thank you. You have a good day. Bye-bye. \n",
            "\n",
            "\n",
            "Saved transcription as /content/drive/MyDrive/WhisperAudio//TextFiles/saved.txt\n",
            "Moved /content/drive/MyDrive/WhisperAudio/saved.mp3 to /content/drive/MyDrive/WhisperAudio/ProcessedAudio/\n"
          ]
        }
      ],
      "source": [
        "# Load all the audio file paths in a Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True) # This will prompt for authorization.\n",
        "\n",
        "# Assuming the audio files are in a folder called \"WhisperAudio\" in the root of the drive\n",
        "audio_folder = \"/content/drive/MyDrive/WhisperAudio/\"\n",
        "\n",
        "# Get a list of all the file paths and names in the folder\n",
        "import os\n",
        "audio_files = []\n",
        "audio_names = []\n",
        "for file in os.listdir(audio_folder):\n",
        "  if file.endswith(\".m4a\") or file.endswith(\".mp3\"):\n",
        "    audio_files.append(audio_folder + file)\n",
        "    audio_names.append(file)\n",
        "\n",
        "for f in audio_files:    \n",
        "  print(f)\n",
        "\n",
        "if len(audio_files) == 0:\n",
        "  print(\"You have no files.\")\n",
        "\n",
        "# Loop through the audio files, split each audio file based on pauses in speech then transcribe them with Whisper.\n",
        "for i, file in enumerate(audio_files): # For each audio file\n",
        "  print(f\"Processing {audio_names[i]}...\")\n",
        "  # Load the audio file and convert it to 16 kHz mono\n",
        "  audio, sr = librosa.load(file, sr=16000, mono=True)\n",
        "  # Detect pauses and split the audio. We use a threshold of -30 dB and a minimum pause length of 0.5 seconds.\n",
        "  pauses = librosa.effects.split(audio, top_db=30, frame_length=2048, hop_length=128)\n",
        "  # Transcribe each segment and concatenate the results\n",
        "  transcription = \"\"\n",
        "  for start, end in pauses: # For each segment\n",
        "    segment = audio[start:end]\n",
        "    # Save the segment as a temporary wav file\n",
        "    temp_file = \"temp.wav\"\n",
        "    sf.write(temp_file, segment, sr, subtype='PCM_16')\n",
        "    if os.path.getsize(temp_file) > 10000:\n",
        "      #continue\n",
        "      # Transcribe the segment with Whisper\n",
        "      result = model.transcribe(temp_file)\n",
        "      text = result[\"text\"]\n",
        "      # Append the text to the transcription\n",
        "      print(len(transcription.split(\" \")), \"words processed\")\n",
        "      transcription += text.strip() + \" \"\n",
        "      # Delete the temporary file\n",
        "      os.remove(temp_file)\n",
        "  # Print the transcription\n",
        "  print(f\"Transcription of {audio_names[i]}:\\n\")\n",
        "  print(transcription)\n",
        "  print(\"\\n\")\n",
        " \n",
        "  # Convert the spaces between sections into paragraph breaks and save the transcription as a txt document in the same folder as MyAudio.\n",
        "  transcription = re.sub(r\"\\s\\s+\", \"\\n\\n\", transcription) # Replace multiple spaces with newlines\n",
        "  text_file = audio_folder + \"/TextFiles/\" + audio_names[i][:-4] + \".txt\" # Create the text file name\n",
        "  with open(text_file, \"w\") as f: # Write the transcription to the text file\n",
        "    f.write(transcription)\n",
        "  print(f\"Saved transcription as {text_file}\")\n",
        "\n",
        "# Move the audio files to \"/content/drive/MyDrive/WhisperAudio/Processed\"\n",
        "import shutil\n",
        "processed_folder = \"/content/drive/MyDrive/WhisperAudio/ProcessedAudio/\"\n",
        "if not os.path.exists(processed_folder): # Create the folder if it does not exist\n",
        "  os.mkdir(processed_folder)\n",
        "for file in audio_files: # Move each audio file to the processed folder\n",
        "  shutil.move(file, processed_folder + os.path.basename(file))\n",
        "  print(f\"Moved {file} to {processed_folder}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}